name: SubjetXbb

data:
  train_file: /share/rcifdata/svanstroud/data/xbb/tutorial/Xbb-hybrid-resampled_scaled_shuffled.h5
  val_file: /share/rcifdata/svanstroud/data/xbb/tutorial/Xbb-hybrid-validation-resampled_scaled_shuffled.h5
  norm_dict: /share/rcifdata/svanstroud/data/xbb/tutorial/Xbb-scale_dict.json
  inputs:
    jet: jets
    track: subjets
  num_jets_train: 5_000_000
  num_jets_val: 500_000
  num_jets_test: -1

trainer:
  max_epochs: 10
  callbacks:
    - class_path: salt.callbacks.Checkpoint
      init_args:
        monitor_loss: val_jet_classification_loss
    - class_path: salt.callbacks.PredictionWriter
      init_args:
        jet_variables:
          - pt
          - eta
          - mass
          - R10TruthLabel_R22v1
          - R10TruthLabel_R22v1_TruthJetMass
          - R10TruthLabel_R22v1_TruthJetPt
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: pytorch_lightning.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 20
    - class_path: pytorch_lightning.callbacks.ModelSummary
      init_args:
        max_depth: 2

model:
  model:
    class_path: salt.models.JetTagger
    init_args:
      init_nets:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: salt.models.InitNet
              init_args:
                name: track
                net:
                  class_path: salt.models.Dense
                  init_args:
                    input_size: 12
                    output_size: &embed_dim 64
                    hidden_layers: [64]
                    activation: &activation SiLU
                    norm_layer: &norm_layer LayerNorm

      gnn:
        class_path: salt.models.TransformerEncoder
        init_args:
          embed_dim: *embed_dim
          num_layers: 2
          mha_config:
            num_heads: 2
            attention:
              class_path: salt.models.ScaledDotProductAttention
            out_proj: False
          dense_config:
            norm_layer: *norm_layer
            activation: *activation
            hidden_layers: [128]
            dropout: &dropout 0.1

      pool_net:
        class_path: salt.models.GlobalAttentionPooling
        init_args:
          input_size: *embed_dim

      tasks:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: salt.models.ClassificationTask
              init_args:
                name: jet_classification
                input_type: jet
                label: flavour_label
                loss: torch.nn.CrossEntropyLoss
                net:
                  class_path: salt.models.Dense
                  init_args:
                    input_size: *embed_dim
                    output_size: 4
                    hidden_layers: [64, 32]
                    activation: *activation
                    norm_layer: *norm_layer
                    dropout: *dropout
